{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOOEVabwKKTp"
   },
   "source": [
    "# Lab 04 - Acquisition functions and Bayesian optimization\n",
    "## Tasks\n",
    "- Demonstrate Bayesian optimization\n",
    "- Solve quadrupole triplet focusing using Bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjJlC-5XKKTr"
   },
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137780,
     "status": "ok",
     "timestamp": 1738377264494,
     "user": {
      "displayName": "Ryan Roussel",
      "userId": "02503318963409515820"
     },
     "user_tz": 360
    },
    "id": "EUmBJsadNqzj",
    "outputId": "dbbb27ab-c8bf-407f-c146-9de17f62ac75"
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "!pip install botorch==0.12.0 gpytorch xopt==2.5.2\n",
    "!pip install cheetah-accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07dm1x6LKKTr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import packages required for BO\n",
    "import torch\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import LogExpectedImprovement\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "uDQxEAkOKKTr"
   },
   "source": [
    "## GP model creation\n",
    "We start by generating two random observations to create the initial GP model (using BoTorch this time). Note that BoTorch does a number of things under the hood, including using Normalization and Standardization transformers to normalize and standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iQ16tcEKKTs"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return torch.sin(2*torch.pi*x) + x + torch.randn_like(x) * 0.01\n",
    "\n",
    "train_x = torch.tensor([0.3,0.5],dtype=torch.double).unsqueeze(-1)\n",
    "train_y = f(train_x)\n",
    "\n",
    "gp = SingleTaskGP(\n",
    "    train_X=train_x,\n",
    "    train_Y=train_y,\n",
    "    input_transform=Normalize(d=1),\n",
    "    outcome_transform=Standardize(m=1),\n",
    ")\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_mll(mll);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "eb4Bb0XSKKTs"
   },
   "source": [
    "### Acquisition function definition\n",
    "Next we define the acquisition function. For this example we use Log Expected Improvement (EI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9k1xk7xkKKTs"
   },
   "outputs": [],
   "source": [
    "acquisition_function = LogExpectedImprovement(gp, best_f=torch.max(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ol_l1O8gKKTs"
   },
   "source": [
    "### Visualize the GP model and the acquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1738377327322,
     "user": {
      "displayName": "Ryan Roussel",
      "userId": "02503318963409515820"
     },
     "user_tz": 360
    },
    "id": "3rQZa3wpKKTs",
    "outputId": "e1548d63-f40f-4fd9-dd94-ab0e2e98fa9d"
   },
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 1, 50)\n",
    "with torch.no_grad():\n",
    "    p = gp.posterior(x.reshape(-1,1,1))\n",
    "\n",
    "    #get the mean\n",
    "    m = p.mean.squeeze()\n",
    "\n",
    "    #get the 2 sigma confidence region around the mean\n",
    "    l,u = p.mvn.confidence_region()\n",
    "    l = l.squeeze()\n",
    "    u = u.squeeze()\n",
    "\n",
    "    # calculate the acquisition function\n",
    "    acqf = acquisition_function(x.reshape(-1,1,1))\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(2,1,sharex=True)\n",
    "ax[1].set_xlabel('x')\n",
    "ax[0].set_ylabel('y')\n",
    "#plot mean and confidence region\n",
    "ax[0].plot(x, m)\n",
    "ax[0].fill_between(x.squeeze(), l, u, alpha = 0.25, lw = 0)\n",
    "\n",
    "ax[1].plot(x, acqf)\n",
    "ax[1].set_ylabel(r\"$\\alpha(x)$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "mWIDMUo5KKTt"
   },
   "source": [
    "### Optimize the acquisition function\n",
    "Use the `optimize_acqf` function in BoTorch to maximize the acquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1738377327322,
     "user": {
      "displayName": "Ryan Roussel",
      "userId": "02503318963409515820"
     },
     "user_tz": 360
    },
    "id": "M2NFT7zsKKTt",
    "outputId": "2ed04705-d812-45d9-9d24-4819985cdd26"
   },
   "outputs": [],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "bounds = torch.stack([torch.zeros(1), torch.ones(1)]).to(torch.double)\n",
    "candidate, acq_value = optimize_acqf(\n",
    "    acquisition_function, bounds=bounds, q=1, num_restarts=5, raw_samples=20,\n",
    ")\n",
    "candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAkzXuYOQCO3"
   },
   "source": [
    "# Basic BO\n",
    "We are going to maximize the following function using Bayesian optimization\n",
    "\n",
    "$$\n",
    "f(x) = \\sin(2\\pi x) + x\n",
    "$$\n",
    "in the domain $[0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **Task**\n",
    "Perform 20 steps of BO to solve the optimization problem. Plot the model and the acquisition function at the end of each optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4350,
     "status": "ok",
     "timestamp": 1738377331671,
     "user": {
      "displayName": "Ryan Roussel",
      "userId": "02503318963409515820"
     },
     "user_tz": 360
    },
    "id": "REw-SUlBKKTu",
    "outputId": "3e1a9de0-8caa-4830-93a3-f7341edeb217"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uVm0H4PPm0T"
   },
   "source": [
    "# Trust region BO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ_7fk6mFZbd"
   },
   "source": [
    "## **Task**\n",
    "Rewrite the optimization loop above to set the acquisition function bounds centered at the location of the current optimum +/- 10\\% of the input domain. Plot the objective function vs iteration for both cases. How does this affect optimization performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c43qSxYmpX4Z"
   },
   "outputs": [],
   "source": [
    "train_x = torch.tensor([0.5],dtype=torch.double).unsqueeze(-1)\n",
    "train_y = f(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sf4Xq_LNpbIE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4307,
     "status": "ok",
     "timestamp": 1738377335976,
     "user": {
      "displayName": "Ryan Roussel",
      "userId": "02503318963409515820"
     },
     "user_tz": 360
    },
    "id": "fcMdZvosKKTu",
    "outputId": "724fb341-225c-4140-9929-b83242eed4e8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-M9GGBVltqv"
   },
   "source": [
    "> **Your answer here** (How does this affect optimization performance?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c27flTomHSIQ"
   },
   "source": [
    " # **Homework**\n",
    "Minimize the beamsize function defined in lab 1, using Xopt's `ExpectedImprovementGenerator`, defined for you below. Note that you can call `X.random_evaluate()` to generate random samples for creating the initial GP model.\n",
    "  See https://xopt.xopt.org/examples/single_objective_bayes_opt/bo_tutorial/ for\n",
    "  an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GP60F1-wq75M"
   },
   "outputs": [],
   "source": [
    "from xopt.generators.bayesian import ExpectedImprovementGenerator\n",
    "from xopt import VOCS\n",
    "\n",
    "vocs = VOCS(\n",
    "    variables={\n",
    "        \"k1\": [0,15],\n",
    "        \"k2\": [-15,0],\n",
    "        \"k3\": [0, 15]\n",
    "    },\n",
    "    objectives={\"beamsize\": \"MINIMIZE\"}\n",
    ")\n",
    "\n",
    "generator = ExpectedImprovementGenerator(vocs=vocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7bgDEhqcKie"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUN9JS6CUykI"
   },
   "source": [
    "# **BONUS Homework (NOT GRADED)**\n",
    "Now solve the multi-objective 2-D ZDT problem from Lab 2 using Mulit-Objective Bayesian Optimization (MOBO) using the `MOBOGenerator` object in Xopt (see https://xopt.xopt.org/examples/multi_objective_bayes_opt/mobo/ for an example). Plot the front projected onto the bunch length vs. horizontal emittance subspace. Plot the acquisition function on the 2D input plane every 5 steps. Finally, calculate the hypervolume of the Pareto front at the end of the optimization run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6csUDM2EVwZV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mWIDMUo5KKTt",
    "tAkzXuYOQCO3",
    "7uVm0H4PPm0T",
    "c27flTomHSIQ",
    "MUN9JS6CUykI"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "csr-psr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
