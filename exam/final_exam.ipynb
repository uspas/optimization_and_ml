{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exam\n",
    "\n",
    "**For this exam, feel free to re-use any code from the previous lab notebooks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "- Use accelerator data to construct a neural network surrogate model, train that model, and demonstrate that it accurately models the data\n",
    "- Use Bayesian optimization to optimize the function and determine the best operational parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/uspas/2021_optimization_and_ml --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#matplotlib graphs will be included in your notebook, next to the code:\n",
    "%matplotlib inline\n",
    "\n",
    "#add PyTorch and TorchVision (used for cropping etc.)\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#import toy accelerator package\n",
    "from uspas_ml.accelerator_toy_models import simple_linarc\n",
    "from uspas_ml.utils import transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset\n",
    "\n",
    "The code below generates samples from \"simulations\" of a beam propagating through a linac followed by an arc:\n",
    "- The input to the simulator are the linac's phase, the arc's R56 coefficient, and the beam final (mean) energy.\n",
    "- The output of the simulator are the bunch length (in meters) and the bunch's RMS energy spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate input samples\n",
    "n = 10000\n",
    "torch.manual_seed(0)\n",
    "inputs = torch.rand((n, 3))\n",
    "\n",
    "#phase +/- 50 deg\n",
    "inputs[:, 0] = inputs[:, 0] * 100.0 - 50.0\n",
    "\n",
    "#r56 +/- 0.5\n",
    "inputs[:,1] = inputs[:,1] - 0.5\n",
    "\n",
    "#final energy [800,1300]*1e6\n",
    "inputs[:,2] = (inputs[:,2] * 500.0 + 800.0) * 1e6\n",
    "\n",
    "print('Inputs:')\n",
    "print(inputs)\n",
    "\n",
    "outputs = []\n",
    "for i in range(n):\n",
    "    outputs += [simple_linarc.propagate(linac_phase = inputs[i][0], \n",
    "                                        arc_r56 = inputs[i][1],\n",
    "                                        linac_final_E = inputs[i][2])]\n",
    "\n",
    "outputs = torch.vstack(outputs)\n",
    "\n",
    "print('Outputs:')\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task:** \n",
    "    Appropriately normalize the input data, and standardize the output data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task:** \n",
    "    Create and train a neural network to model this data, i.e. for each data point, the neural network should take the above 3 (normalized) input features and predict the above 2 (normalized) output features. \n",
    "    \n",
    "In order to show that the neural network works as expected and that the training roughly converged, plot the evolution of the loss function - both for the training dataset and test dataset - during training. (Use the first 7000 data points as the training set, and the remaining 3000 data points as the test set.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task:** \n",
    "    Use Bayesian optimization to minimize the bunch length (i.e. the first of the 2 features that are returned by `simple_linarc`) with respect to phase, r56, and final_energy (i.e. the 3 input features that we passed to `simple_linarc` when previously generating the dataset for the neural network). \n",
    "    \n",
    "Use the first 10 elements of the previously-created arrays `inputs` and `outputs` as the initial dataset on which to fit the initial Gaussian Process (at the beginning of Bayesian optimization). Then, at each iteration of Bayesian optimization, call the `simple_linarc` function on the new candidate point. \n",
    "    \n",
    "Run 6 steps of Bayesian optimization and print the values of the bunch length obtained at each iteration. What is the best value obtained so far?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
